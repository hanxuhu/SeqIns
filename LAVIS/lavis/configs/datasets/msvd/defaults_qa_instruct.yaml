 # Copyright (c) 2022, salesforce.com, inc.
 # All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause

datasets:
  msvd_qa_instruct: # name of the dataset builder
    # data_dir: ${env.data_dir}/datasets
    data_type: videos # [images|videos|features]
    
    vis_processor:
      train:
        name: alpro_video_train
        n_frms: 4
        image_size: 224
        min_scale: 0.9
        max_scale: 1.0
        full_video: True
      eval:
        name: alpro_video_eval
        n_frms: 4
        image_size: 224
        min_scale: 0.9
        max_scale: 1.0
        full_video: True
    
    text_processor:
      train:
        name: blip_instruction
        task: qa
        modality: video
      eval:
        name: blip_question
        
    build_info:
      # Be careful not to append minus sign (-) before split to avoid itemizing
      annotations:
        train:
          url: https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/msvd/qa_train.json
          storage: msvd/annotations/qa_train.json
        val:
          url: https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/msvd/qa_val.json
          storage: msvd/annotations/qa_val.json
        test:
          url: https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/msvd/qa_test.json
          storage: msvd/annotations/qa_test.json
        ans2label:
          url: https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/msvd/train_ans2label.json
          storage: msvd/annotations/qa_ans2label.json
      videos:
        storage: /export/share/datasets/vision_language/msvd/videos

      instance_id_key: question_id
