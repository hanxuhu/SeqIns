 # Copyright (c) 2022, salesforce.com, inc.
 # All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause

datasets:
  iconqa:
    # data_dir: ${env.data_dir}/datasets
    data_type: images # [images|videos|features]

    vis_processor:
      train:
        name: "clip_image_train"
        image_size: 224
      eval:
        name: "clip_image_eval"
        image_size: 224

    
    text_processor:
      train:
        name: blip_question
      eval:
        name: blip_question
        
    build_info:
      # Be careful not to append minus sign (-) before split to avoid itemizing
      annotations:
        train:
          url:
            - https://storage.googleapis.com/sfr-xinstructblip-data-research/data/iconqa/annotations_train.json
            # - /export/share/datasets/vision_language/iconqa/annotations_train.json
          storage:
            - iconqa/annotations/train.json
            # - /export/share/datasets/vision_language/iconqa/annotations_train.json
        val:
          url:
            - https://storage.googleapis.com/sfr-xinstructblip-data-research/data/iconqa/annotations_val.json
            # - /export/share/datasets/vision_language/iconqa/annotations_val.json
          storage:
            - iconqa/annotations/val.json
            # - /export/share/datasets/vision_language/iconqa/annotations_val.json
        test:
          url:
            - https://storage.googleapis.com/sfr-xinstructblip-data-research/data/iconqa/annotations_test.json
            # - /export/share/datasets/vision_language/iconqa/annotations_test.json
          storage:
            - iconqa/annotations/test.json
            # - /export/share/datasets/vision_language/iconqa/annotations_test.json
      images:
          storage: /export/share/datasets/vision_language/iconqa/all_images/

